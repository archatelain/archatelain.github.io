---
layout: default
---

<!-- ## Research Summary -->
<!-- <details class="space-after">
<summary>For non-academics </summary><br>
In my PhD I have been working on the media conducting both applied and methodological research. <br><br>

My main research project is concerned with how consumers have been reacting to major sexual violence accusations in the French music market. Using detailed market data of streaming consumption in France for 8 years, I am using causal inference methods to identify whether consumers turn away from artists following major scandals. To retrieve major scandals and control for consumers awareness of the latter, I have developed a <em>bottom-up</em> approach retrieving artists' presence on the internet and combining these information with automated information retrieval methods. <br><br>

I have also been working on the French national press, looking at how media biases have evolved over the past 20 years. In this project I am using natural language processing methods and language models to develop a fine-grained measure of news slanting. <br><br> 

Finally, I am very much interested in recent advances in natural language processing and language models. I am conducting a thorough scientific watch both on the methodological evolutions and the use of these methods in social sciences. I have already written a short comment on the latter (see below) and am co-organizing the CREST <a href="https://www.css.cnrs.fr/nlp-social-sciences-seminar-program/">NLP & Social Sciences seminar</a>.  
</details> -->


## Publication

[**The dangers of using proprietary LLMs for research**](https://rdcu.be/dwdJE) \\
(with [Ana Macanovic](https://amacanovic.github.io/), [Etienne Ollion](https://ollion.cnrs.fr/), [Rubing Shen](https://medialab.sciencespo.fr/equipe/rubing-shen/)) \\
*Nature Machine Intelligence*, 6(1), 4-5 (2024)


## Work in progress

**No Bad Buzz?: Methods and Evidence from Sexual Misconduct Scandals in the Music Industry** 

<!-- <details class="space-after">
<summary>abstract</summary>
<p>This paper studies the effect of sexual and domestic violence allegations on music artists' commercial success. Using market data on music streaming in France I find that high-profile sexual misconduct scandals lead to a significant drop of an average of 9% of number of plays on music streaming platforms in the following year -- the scandals are retrieved in the national press using a custom event detection pipeline and the effect is estimated using a stacked synthetic control method. Converting it to total reputation cost, including all types of artists income sources, this represents a loss of €32,544 in the following year. Exploratory heterogeneity analysis suggest that hiphop artists are associated with a stronger scandal effect than others, highlighting the heterogeneity in the scandals effect studied. These results provide first evidence that some consumer sanctioning is at play following such scandals and thus contributes to the general discussion on which channels of sanctions could curb permissive industry cultures with regards to sexual misconduct.</p>
</details> -->


**BenCSSMark: Towards An Open, Collective Benchmark for Computational Social Sciences** \\
(with Etienne Ollion, Qianwen Guan, Diandra Fabre, Marie Candito, Lorraine Goeuriot, Emile Chapuis, Abdelkrim Beloued, Nicolas Hervé, Didier Schwab)


**Media Slant as Political Refraction: Measuring the Ideological Diversity of the French Media Landscape** \\
(with [Felix Lennert](https://felix-lennert.netlify.app/), [Etienne Ollion](https://ollion.cnrs.fr/), [Rubing Shen](https://medialab.sciencespo.fr/equipe/rubing-shen/))

**"Everyone Knows That": Detecting Rhetorics Usage on the French Radio** \\
(with Yacine Chitour and [Etienne Ollion](https://ollion.cnrs.fr/))



## Other

[**ChatGPT for Text Annotation? Mind the Hype!**](https://doi.org/10.31235/osf.io/x58kn) \\
(with [Ana Macanovic](https://amacanovic.github.io/), [Etienne Ollion](https://ollion.cnrs.fr/), [Rubing Shen](https://medialab.sciencespo.fr/equipe/rubing-shen/)) \\
*SocArXiv*, (2023)
    <!-- <details class="space-after">
    <summary>abstract</summary>
    <p><em>In the past months, researchers have enthusiastically discussed the relevance of zero- or few-shot classifiers like ChatGPT for text annotation. Should these models prove to be performant, they would open up new continents for research, and beyond. To assess the merits and limits of this approach, we conducted a systematic literature review. Reading all the articles doing zero or few-shot text annotation in the human and social sciences, we found that these few- shot learners offer enticing, yet mixed results on text annotation tasks. The performance scores can vary widely, with some being average and some being very low. Besides, zero or few-shot models are often outperformed by models fine-tuned with human annotations. Our findings thus suggest that, to date, the evidence about their effectiveness remains partial, but also that their use raises several important questions about the reproducibility of results, about privacy and copyright issues, and about the primacy of the English language. While we definitely believe that there are numerous ways to harness this powerful technology productively, we also need to harness it without falling for the hype.</em></p></details> -->
